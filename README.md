# Kaggle-Toxic-Comment-Classification-Challenge
To build a multi-headed model thatâ€™s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate.

Word embedding done by glove.6b 100d vectors

1.kaggle_bi.py is a simple Bi-LSTM model,  
2.kaggle_cnn.py is a model built using cnn, 
3.kaggle_bi3.py is model built using bi-lstm and cnn,
